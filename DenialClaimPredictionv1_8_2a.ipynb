{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "N8T7J6ooJ1Ac"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ayxbhg\\.venvs\\py313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import pyodbc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    average_precision_score, roc_auc_score, precision_recall_curve,\n",
        "    f1_score, precision_score, recall_score, confusion_matrix, classification_report\n",
        ")\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score, auc\n",
        "from xgboost import XGBClassifier\n",
        "import shap\n",
        "import os\n",
        "from datetime import datetime\n",
        "from joblib import dump, load\n",
        "import warnings\n",
        "from sklearn.exceptions import FitFailedWarning\n",
        "import xgboost as xgb\n",
        "import optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-894FADJ-TZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Connection successful!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ayxbhg\\AppData\\Local\\Temp\\ipykernel_61028\\2961411225.py:25: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  chunk_generator = pd.read_sql(sql_query, cnxn, chunksize=chunksize)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded chunk 1 with 100000 rows\n",
            "Loaded chunk 2 with 100000 rows\n",
            "Loaded chunk 3 with 100000 rows\n",
            "Loaded chunk 4 with 100000 rows\n",
            "Loaded chunk 5 with 100000 rows\n",
            "Loaded chunk 6 with 100000 rows\n",
            "Loaded chunk 7 with 100000 rows\n",
            "Loaded chunk 8 with 100000 rows\n",
            "Loaded chunk 9 with 100000 rows\n",
            "Loaded chunk 10 with 100000 rows\n",
            "Loaded chunk 11 with 100000 rows\n",
            "Loaded chunk 12 with 100000 rows\n",
            "Loaded chunk 13 with 100000 rows\n",
            "Loaded chunk 14 with 100000 rows\n",
            "Loaded chunk 15 with 100000 rows\n",
            "Loaded chunk 16 with 100000 rows\n",
            "Loaded chunk 17 with 100000 rows\n",
            "Loaded chunk 18 with 100000 rows\n",
            "Loaded chunk 19 with 100000 rows\n",
            "Loaded chunk 20 with 100000 rows\n",
            "Loaded chunk 21 with 100000 rows\n",
            "Loaded chunk 22 with 100000 rows\n",
            "Loaded chunk 23 with 100000 rows\n",
            "Loaded chunk 24 with 100000 rows\n",
            "Loaded chunk 25 with 96674 rows\n",
            "\n",
            " Total rows combined: 2496674\n",
            "\n",
            "Total rows returned: 2496674\n",
            "\n",
            "Top 5 rows of the DataFrame:\n",
            "  Clinic  TPCLIID  LIATPCLIid   ServiceDt                     Service  \\\n",
            "0    AHK    10541       10541  2025-06-15  Methadone Maintenance Week   \n",
            "1    AHK    10628       10628  2025-06-22  Methadone Maintenance Week   \n",
            "2    AHK    10706       10706  2025-06-29  Methadone Maintenance Week   \n",
            "3    AHK    11295       11295  2025-07-06  Methadone Maintenance Week   \n",
            "4    AHK    10810       10810  2025-07-13  Methadone Maintenance Week   \n",
            "\n",
            "     ClaimID  AmountCharged CPTCode  ClientID ClaimBillDate  ... TotalAdj  \\\n",
            "0  143008584         254.93   H0020       111    2025-06-16  ...      0.0   \n",
            "1  143008669         254.93   H0020       111    2025-06-23  ...      0.0   \n",
            "2  143008744         254.93   H0020       111    2025-06-30  ...      0.0   \n",
            "3  143009367         254.93   H0020       111    2025-08-20  ...      0.0   \n",
            "4  143008898         254.93   H0020       111    2025-07-14  ...      0.0   \n",
            "\n",
            "  TotalVoid CoPay Deduc  CoIns CltResp Balance MultiFlag  SameDayCli  \\\n",
            "0       0.0   0.0   0.0    0.0     0.0    0.00         N           0   \n",
            "1       0.0   0.0   0.0    0.0     0.0    0.00         N           0   \n",
            "2       0.0   0.0   0.0    0.0     0.0    0.00         N           0   \n",
            "3       0.0   0.0   0.0    0.0     0.0    0.00         N           0   \n",
            "4       0.0   0.0   0.0    0.0     0.0  254.93         Z           0   \n",
            "\n",
            "   DaysBetServiceToBilling  \n",
            "0                        1  \n",
            "1                        1  \n",
            "2                        1  \n",
            "3                       45  \n",
            "4                        1  \n",
            "\n",
            "[5 rows x 29 columns]\n"
          ]
        }
      ],
      "source": [
        "def read_from_azure_in_chunks(chunksize=100000):\n",
        "    try:\n",
        "        # Set up connection\n",
        "        cnxn = pyodbc.connect(\n",
        "            'Driver={ODBC Driver 17 for SQL Server};'\n",
        "            'Server=bhgazuresql01.database.windows.net;'\n",
        "            'Authentication=ActiveDirectoryPassword;'\n",
        "            'Database=BHG_DR;'\n",
        "            'UID=xxxxxxxxxx;'\n",
        "            'PWD=xxxxxxxxxx;'\n",
        "        )\n",
        "        print(\"Connection successful!\")\n",
        "\n",
        "        # Define SQL query\n",
        "        sql_query = \"\"\"\n",
        "        SELECT\n",
        "            *\n",
        "        FROM\n",
        "            pats.vw_ClaimsDenialPrediction\n",
        "        WHERE\n",
        "            ClaimBillDate >= dateadd(year,-1,cast(getdate() as date)) AND LIATPCLIid IS NOT NULL\n",
        "        \"\"\"\n",
        "\n",
        "        # Load data in chunks and concatenate\n",
        "        chunk_generator = pd.read_sql(sql_query, cnxn, chunksize=chunksize)\n",
        "        chunks = []\n",
        "        for i, chunk in enumerate(chunk_generator):\n",
        "            print(f\"Loaded chunk {i+1} with {len(chunk)} rows\")\n",
        "            chunks.append(chunk)\n",
        "\n",
        "        full_df = pd.concat(chunks, ignore_index=True)\n",
        "        print(f\"\\n Total rows combined: {len(full_df)}\")\n",
        "        return full_df\n",
        "\n",
        "    except pyodbc.DatabaseError as e:\n",
        "        print('Database Error:', str(e))\n",
        "    except pyodbc.Error as e:\n",
        "        print('Connection Error:', str(e))\n",
        "    finally:\n",
        "        try:\n",
        "            cnxn.close()\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    df = read_from_azure_in_chunks()\n",
        "\n",
        "    if df is not None:\n",
        "        print(f\"\\nTotal rows returned: {len(df)}\\n\")\n",
        "        print(\"Top 5 rows of the DataFrame:\")\n",
        "        print(df.head())\n",
        "    else:\n",
        "        print(\"No data returned.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Total rows before deduplication: 2496674\n",
            "No duplication detected.\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\nTotal rows before deduplication: {len(df)}\")\n",
        "\n",
        "duplicate_count = df.duplicated().sum()\n",
        "if duplicate_count == 0:\n",
        "    print(\"No duplication detected.\")\n",
        "else:\n",
        "    print(f\"Number of duplicated rows: {duplicate_count}\")\n",
        "    df = df.drop_duplicates()\n",
        "    print(f\"Total rows after deduplication: {len(df)}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Clinic                           0\n",
            "TPCLIID                          0\n",
            "LIATPCLIid                       0\n",
            "ServiceDt                        0\n",
            "Service                          0\n",
            "ClaimID                          0\n",
            "AmountCharged                    0\n",
            "CPTCode                          0\n",
            "ClientID                         0\n",
            "ClaimBillDate                    0\n",
            "Payer                            0\n",
            "Provider                         0\n",
            "AuthStatus                       0\n",
            "eligStatus                       0\n",
            "DenialFlag                       0\n",
            "lastActDt                        0\n",
            "cliANSI1                   1617902\n",
            "cliANSI2                   2379914\n",
            "TotalPaid                        0\n",
            "TotalAdj                         0\n",
            "TotalVoid                        0\n",
            "CoPay                            0\n",
            "Deduc                            0\n",
            "CoIns                            0\n",
            "CltResp                          0\n",
            "Balance                          0\n",
            "MultiFlag                        0\n",
            "SameDayCli                       0\n",
            "DaysBetServiceToBilling          0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(df.isnull().sum()) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns dropped: ['cliANSI1', 'cliANSI2', 'TotalPaid', 'TotalAdj', 'TotalVoid', 'MultiFlag', 'CoPay', 'Deduc', 'CoIns', 'CltResp', 'ClientResp.', 'Balance', 'tpcliAge']\n",
            "Rows dropped due to NULLs : 0\n",
            "Total rows after cleaning: 2496674\n",
            "Sampled training rows: 1000000\n",
            "Unseen (sampled) rows: 10000\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Full pipeline (native categoricals, random UNSEEN sampling, Optuna tuning, SHAP):\n",
        "- Keep `tpccltID` (do NOT drop it).\n",
        "- Use XGBoost **native categoricals** (no one-hot) with `enable_categorical=True`.\n",
        "- Build **UNSEEN** by random sampling from the remainder after taking the training sample (no date cutoff).\n",
        "- Engineer compact **date features** and drop raw datetime columns before modeling.\n",
        "- Optuna tunes on CV PR-AUC (wider search for more trial diversity); choose threshold from OOF.\n",
        "- Compare **F1/precision/recall** at each trial's OOF-chosen threshold on TEST and UNSEEN.\n",
        "- Save artifacts; score UNSEEN and Azure data; export **SHAP Top-K** explanations.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# ======================================\n",
        "# CLEANUP + PREP\n",
        "# ======================================\n",
        "\n",
        "# Drop unnecessary columns\n",
        "cols_to_drop = [\n",
        "    'cliANSI1', 'cliANSI2', 'TotalPaid', 'TotalAdj', 'TotalVoid','MultiFlag',\n",
        "    'CoPay', 'Deduc', 'CoIns', 'CltResp', 'ClientResp.', 'Balance', 'tpcliAge'\n",
        "]\n",
        "df.drop(columns=cols_to_drop, inplace=True, errors='ignore')\n",
        "print(f\"Columns dropped: {cols_to_drop}\")\n",
        "\n",
        "# Drop rows with nulls in important columns\n",
        "before_dropna = len(df)\n",
        "df = df.dropna(subset=['ServiceDt', 'Service', 'CPTCode'])\n",
        "after_dropna = len(df)\n",
        "print(f\"Rows dropped due to NULLs : {before_dropna - after_dropna}\")\n",
        "print(f\"Total rows after cleaning: {len(df)}\")\n",
        "\n",
        "# Step 1: Drop ID columns (KEEP tpccltID)\n",
        "df = df.drop(columns=['TPCLIID', 'ClaimID', 'LIATPCLIid'], errors='ignore')\n",
        "\n",
        "# Step 2: Target type\n",
        "df['DenialFlag'] = df['DenialFlag'].astype('category')\n",
        "\n",
        "# Ensure datetime dtype for feature engineering\n",
        "for c in ['ClaimBillDate', 'ServiceDt', 'lastActDt']:\n",
        "    df[c] = pd.to_datetime(df[c], errors='coerce')\n",
        "\n",
        "# -------------------------------\n",
        "# Helper: Date feature engineering (drop raw datetimes)\n",
        "# -------------------------------\n",
        "\n",
        "def add_date_features(df_in: pd.DataFrame) -> pd.DataFrame:\n",
        "    dfX = df_in.copy()\n",
        "    # Ensure datetime\n",
        "    for c in ['ServiceDt', 'ClaimBillDate', 'lastActDt']:\n",
        "        if c in dfX.columns:\n",
        "            dfX[c] = pd.to_datetime(dfX[c], errors='coerce')\n",
        "\n",
        "    # Gaps & recency\n",
        "    if 'ServiceDt' in dfX.columns and 'ClaimBillDate' in dfX.columns:\n",
        "        dfX['days_claim_from_service'] = (dfX['ClaimBillDate'] - dfX['ServiceDt']).dt.days\n",
        "    if 'lastActDt' in dfX.columns and 'ClaimBillDate' in dfX.columns:\n",
        "        dfX['days_claim_from_lastAct'] = (dfX['ClaimBillDate'] - dfX['lastActDt']).dt.days\n",
        "    if 'ServiceDt' in dfX.columns:\n",
        "        min_service = dfX['ServiceDt'].min()\n",
        "        dfX['service_age_days'] = (dfX['ServiceDt'] - min_service).dt.days\n",
        "\n",
        "    # Calendar parts\n",
        "    if 'ServiceDt' in dfX.columns:\n",
        "        dfX['service_dow'] = dfX['ServiceDt'].dt.weekday.astype('category')  # 0..6\n",
        "    if 'ClaimBillDate' in dfX.columns:\n",
        "        dfX['claim_month'] = dfX['ClaimBillDate'].dt.month.astype('category')  # 1..12\n",
        "        dfX['claim_week']  = dfX['ClaimBillDate'].dt.isocalendar().week.astype('int32')\n",
        "\n",
        "    # Clip extreme gaps\n",
        "    for c in ['days_claim_from_service', 'days_claim_from_lastAct', 'service_age_days']:\n",
        "        if c in dfX.columns:\n",
        "            dfX[c] = dfX[c].clip(-3650, 36500)\n",
        "\n",
        "    # Drop raw datetime columns\n",
        "    dfX = dfX.drop(columns=['ServiceDt', 'ClaimBillDate', 'lastActDt'], errors='ignore')\n",
        "    return dfX\n",
        "\n",
        "# --------------------------------------\n",
        "# Build TRAIN sample and random UNSEEN\n",
        "# --------------------------------------\n",
        "\n",
        "# Use full df as pool\n",
        "df_train_pool = df.copy()\n",
        "\n",
        "# --- Randomly sample up to 1,000,000 rows from training pool ---\n",
        "n_sample = min(1_000_000, len(df_train_pool))\n",
        "df_sample = df_train_pool.sample(n=n_sample, random_state=123)\n",
        "print(\"Sampled training rows:\", df_sample.shape[0])\n",
        "\n",
        "# --- UNSEEN: sample from remainder (no date logic) ---\n",
        "remainder = df_train_pool.drop(index=df_sample.index)\n",
        "n_unseen = min(10_000, len(remainder))\n",
        "df_unseen = remainder.sample(n=n_unseen, random_state=456).copy()\n",
        "print(\"Unseen (sampled) rows:\", df_unseen.shape[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NaN counts in DenialFlag by ClaimBillDate (overall):\n",
            "Empty DataFrame\n",
            "Columns: [ClaimBillDate, NaN_DenialFlag_Count]\n",
            "Index: []\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# (Optional) QC: NaN DenialFlag by ClaimBillDate on the *original* df before dates are dropped\n",
        "try:\n",
        "    nan_counts = (\n",
        "        df.loc[df['DenialFlag'].isna()]\n",
        "          .groupby(df['ClaimBillDate'].dt.date)\n",
        "          .size()\n",
        "          .reset_index(name='NaN_DenialFlag_Count')\n",
        "          .sort_values('NaN_DenialFlag_Count', ascending=False)\n",
        "    )\n",
        "    print(\"NaN counts in DenialFlag by ClaimBillDate (overall):\")\n",
        "    print(nan_counts.head(20))\n",
        "except Exception as _e:\n",
        "    print(\"[Info] Skipped NaN-by-date QC:\", _e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train sample shape: (1000000, 12)\n",
            "X_train: (600000, 11) X_val: (200000, 11) X_test: (200000, 11)\n",
            "y_train: (600000,) y_val: (200000,) y_test: (200000,)\n",
            "Ratio of 1 in y_train: 0.35206166666666666\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# --- Drop raw datetime columns (no date features) ---\n",
        "drop_dt = ['ServiceDt', 'ClaimBillDate', 'lastActDt']\n",
        "df_sample = df_sample.drop(columns=drop_dt, errors='ignore')\n",
        "df_unseen = df_unseen.drop(columns=drop_dt, errors='ignore')\n",
        "\n",
        "\n",
        "# ======================================\n",
        "# Model matrix (native categorical)\n",
        "# ======================================\n",
        "\n",
        "# Identify categorical predictor columns (exclude target)\n",
        "categorical_cols = [\n",
        "    c for c in df_sample.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "    if c != 'DenialFlag'\n",
        "]\n",
        "# Ensure `tpccltID` included as categorical if present\n",
        "if 'tpccltID' in df_sample.columns and 'tpccltID' not in categorical_cols:\n",
        "    categorical_cols.append('tpccltID')\n",
        "\n",
        "# Cast to pandas 'category'\n",
        "for c in categorical_cols:\n",
        "    if c in df_sample.columns:\n",
        "        df_sample[c] = df_sample[c].astype('category')\n",
        "    if c in df_unseen.columns:\n",
        "        df_unseen[c] = df_unseen[c].astype('category')\n",
        "\n",
        "# Build modeling frame (drop NA target)\n",
        "df_model = df_sample[df_sample['DenialFlag'].notna()].copy()\n",
        "\n",
        "# X / y\n",
        "y = df_model['DenialFlag'].astype(int)\n",
        "X = df_model.drop(columns=['DenialFlag'])\n",
        "\n",
        "# Lock categorical dtypes from X\n",
        "cat_dtypes = {c: X[c].dtype for c in categorical_cols if c in X.columns}\n",
        "\n",
        "# --- Split: 20% test, then 25% of remaining as val (=> 56/14/30 overall) ---\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, random_state=123, stratify=y\n",
        ")\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train_full, y_train_full, test_size=0.25, random_state=123, stratify=y_train_full\n",
        ")\n",
        "\n",
        "# Re-apply categorical dtypes consistently\n",
        "for c, dt in cat_dtypes.items():\n",
        "    if c in X_train: X_train[c] = X_train[c].astype(dt)\n",
        "    if c in X_val:   X_val[c]   = X_val[c].astype(dt)\n",
        "    if c in X_test:  X_test[c]  = X_test[c].astype(dt)\n",
        "\n",
        "print(\"Train sample shape:\", df_sample.shape)\n",
        "print(\"X_train:\", X_train.shape, \"X_val:\", X_val.shape, \"X_test:\", X_test.shape)\n",
        "print(\"y_train:\", y_train.shape, \"y_val:\", y_val.shape, \"y_test:\", y_test.shape)\n",
        "print(\"Ratio of 1 in y_train:\", y_train.mean())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Predictors] Using 11 columns for training.\n",
            "• Feature columns: ['Clinic', 'Service', 'AmountCharged', 'CPTCode', 'ClientID', 'Payer', 'Provider', 'AuthStatus', 'eligStatus', 'SameDayCli', 'DaysBetServiceToBilling']\n",
            "• Categorical (7): ['Clinic', 'Service', 'CPTCode', 'Payer', 'Provider', 'AuthStatus', 'eligStatus']\n",
            "• Numeric/Other (4): ['AmountCharged', 'ClientID', 'SameDayCli', 'DaysBetServiceToBilling']\n"
          ]
        }
      ],
      "source": [
        "# X / y\n",
        "y = df_model['DenialFlag'].astype(int)\n",
        "X = df_model.drop(columns=['DenialFlag'])\n",
        "\n",
        "# === NEW: Inspect and record predictor columns used for training ===\n",
        "feature_cols = X.columns.tolist()\n",
        "\n",
        "# Sanity check: make sure dropped datetime columns didn't sneak back in\n",
        "leaked_dt = set(drop_dt).intersection(feature_cols)\n",
        "assert not leaked_dt, f\"Unexpected datetime columns in features: {leaked_dt}\"\n",
        "\n",
        "# Helpful breakdown\n",
        "cat_in_X = [c for c in categorical_cols if c in feature_cols]\n",
        "num_in_X = [c for c in feature_cols if c not in cat_in_X]\n",
        "\n",
        "print(f\"[Predictors] Using {len(feature_cols)} columns for training.\")\n",
        "print(\"• Feature columns:\", feature_cols)\n",
        "print(f\"• Categorical ({len(cat_in_X)}): {cat_in_X}\")\n",
        "print(f\"• Numeric/Other ({len(num_in_X)}): {num_in_X}\")\n",
        "\n",
        "# (Optional) Persist the feature list for future runs/audits\n",
        "# pd.Series(feature_cols, name=\"feature\").to_csv(\"training_feature_columns.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# ======================================\n",
        "# Helpers\n",
        "# ======================================\n",
        "\n",
        "def pick_threshold_max_f1(y_true, proba, grid=None):\n",
        "    if grid is None:\n",
        "        grid = np.linspace(0.01, 0.99, 99)\n",
        "    best = (-1.0, 0.5, 0.0, 0.0)  # f1, thr, p, r\n",
        "    for thr in grid:\n",
        "        pred = (proba >= thr).astype(int)\n",
        "        p = precision_score(y_true, pred, zero_division=0)\n",
        "        r = recall_score(y_true, pred, zero_division=0)\n",
        "        f1 = f1_score(y_true, pred, zero_division=0)\n",
        "        if f1 > best[0]:\n",
        "            best = (f1, float(thr), float(p), float(r))\n",
        "    return best[1], best[0], best[2], best[3]\n",
        "\n",
        "\n",
        "def evaluate_at_threshold(y_true, proba, threshold=0.5):\n",
        "    pred = (proba >= threshold).astype(int)\n",
        "    cm = confusion_matrix(y_true, pred, labels=[0, 1])\n",
        "    metrics = {\n",
        "        \"precision\": precision_score(y_true, pred, zero_division=0),\n",
        "        \"recall\": recall_score(y_true, pred, zero_division=0),\n",
        "        \"f1\": f1_score(y_true, pred, zero_division=0),\n",
        "        \"pr_auc\": average_precision_score(y_true, proba),\n",
        "    }\n",
        "    clsrep = classification_report(y_true, pred, digits=4)\n",
        "    return cm, metrics, clsrep\n",
        "\n",
        "\n",
        "def print_results(model_name, cm, metrics, clsrep):\n",
        "    print(f\"=== {model_name} RESULTS ===\")\n",
        "    print(\"Confusion Matrix [rows=true 0/1, cols=pred 0/1]:\", cm)\n",
        "    print(\"Metrics:\")\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"  {k}: {v:.5f}\")\n",
        "    print(\"Classification Report:\", clsrep)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "scale_pos_weight (initial) = 1.840\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ======================================\n",
        "# Assemble train+val, imbalance weight\n",
        "# ======================================\n",
        "X_trval = pd.concat([X_train, X_val], axis=0)\n",
        "Y_trval = pd.concat([y_train, y_val], axis=0)\n",
        "\n",
        "# Ensure cat dtypes on X_trval\n",
        "for c, dt in cat_dtypes.items():\n",
        "    if c in X_trval: X_trval[c] = X_trval[c].astype(dt)\n",
        "\n",
        "pos = int(np.sum((y_train == 1).astype(int)))\n",
        "neg = int(np.sum((y_train == 0).astype(int)))\n",
        "scale_pos_weight = float(neg / max(pos, 1))\n",
        "print(f\"scale_pos_weight (initial) = {scale_pos_weight:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-09-09 17:36:12,567] A new study created in memory with name: no-name-d4710e2d-4aa4-454a-9021-7553fe2bcbdd\n",
            "[I 2025-09-09 17:48:55,833] Trial 0 finished with value: 0.892223394268213 and parameters: {'eta': 0.16282276974018148, 'max_depth': 4, 'min_child_weight': 5.966661742985204, 'subsample': 0.85, 'colsample_bytree': 0.7, 'reg_lambda': 1.4138305642553758e-06, 'reg_alpha': 7.254507810340025e-06, 'gamma': 3.7997552301502155, 'grow_policy': 'lossguide', 'max_bin': 64, 'max_cat_to_onehot': 1, 'sampling_method': 'uniform', 'scale_pos_weight': 2.532254762890173}. Best is trial 0 with value: 0.892223394268213.\n",
            "[I 2025-09-09 17:56:53,403] Trial 1 finished with value: 0.901327056753425 and parameters: {'eta': 0.12772060229585225, 'max_depth': 12, 'min_child_weight': 1.6323309366572076, 'subsample': 0.85, 'colsample_bytree': 1.0, 'reg_lambda': 1.0100791325912743e-06, 'reg_alpha': 0.11936197780746717, 'gamma': 4.742139397500581, 'grow_policy': 'depthwise', 'max_bin': 256, 'max_cat_to_onehot': 10, 'sampling_method': 'uniform', 'scale_pos_weight': 1.9551333157259125}. Best is trial 1 with value: 0.901327056753425.\n",
            "[I 2025-09-09 18:15:25,651] Trial 2 finished with value: 0.8994018064614913 and parameters: {'eta': 0.04697047669018152, 'max_depth': 7, 'min_child_weight': 2.90230882998834, 'subsample': 0.85, 'colsample_bytree': 1.0, 'reg_lambda': 25.062518341026376, 'reg_alpha': 1.4043590257820446, 'gamma': 0.2570693364568599, 'grow_policy': 'lossguide', 'max_bin': 128, 'max_cat_to_onehot': 1, 'sampling_method': 'uniform', 'scale_pos_weight': 3.971710393078628}. Best is trial 1 with value: 0.901327056753425.\n",
            "[I 2025-09-09 18:29:19,085] Trial 3 finished with value: 0.8908870001747207 and parameters: {'eta': 0.037758563453951205, 'max_depth': 6, 'min_child_weight': 1.9816991572713458, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_lambda': 0.152562902070625, 'reg_alpha': 1.8921097630208307e-05, 'gamma': 9.609800679210256, 'grow_policy': 'depthwise', 'max_bin': 256, 'max_cat_to_onehot': 10, 'sampling_method': 'uniform', 'scale_pos_weight': 2.2779482463901286}. Best is trial 1 with value: 0.901327056753425.\n",
            "[I 2025-09-09 18:42:43,648] Trial 4 finished with value: 0.8880440527925654 and parameters: {'eta': 0.060248669662813094, 'max_depth': 6, 'min_child_weight': 4.246388142831331, 'subsample': 0.5, 'colsample_bytree': 1.0, 'reg_lambda': 3.832262501815315e-06, 'reg_alpha': 17.823690023270043, 'gamma': 9.49148528741558, 'grow_policy': 'depthwise', 'max_bin': 256, 'max_cat_to_onehot': 10, 'sampling_method': 'uniform', 'scale_pos_weight': 5.605664787521135}. Best is trial 1 with value: 0.901327056753425.\n",
            "[I 2025-09-09 18:57:07,431] Trial 5 finished with value: 0.8929321423648447 and parameters: {'eta': 0.112405958432679, 'max_depth': 6, 'min_child_weight': 4.651610222172314, 'subsample': 0.5, 'colsample_bytree': 0.7, 'reg_lambda': 0.0025067533497232777, 'reg_alpha': 0.10499369173891612, 'gamma': 7.697015097612096, 'grow_policy': 'lossguide', 'max_bin': 64, 'max_cat_to_onehot': 10, 'sampling_method': 'uniform', 'scale_pos_weight': 4.410626037940812}. Best is trial 1 with value: 0.901327056753425.\n",
            "[I 2025-09-09 19:10:13,289] Trial 6 finished with value: 0.8912022316299293 and parameters: {'eta': 0.09764081210321539, 'max_depth': 9, 'min_child_weight': 5.649326382512832, 'subsample': 0.5, 'colsample_bytree': 0.7, 'reg_lambda': 1.5288157460456193, 'reg_alpha': 0.1722538846569082, 'gamma': 9.433636129974023, 'grow_policy': 'depthwise', 'max_bin': 256, 'max_cat_to_onehot': 10, 'sampling_method': 'uniform', 'scale_pos_weight': 1.3567491316912348}. Best is trial 1 with value: 0.901327056753425.\n",
            "[I 2025-09-09 19:26:05,873] Trial 7 finished with value: 0.8956303339934248 and parameters: {'eta': 0.03243959806831978, 'max_depth': 8, 'min_child_weight': 1.7951257045425861, 'subsample': 0.85, 'colsample_bytree': 1.0, 'reg_lambda': 8.332587622827803e-06, 'reg_alpha': 0.3733658795578974, 'gamma': 6.4884976963361405, 'grow_policy': 'lossguide', 'max_bin': 64, 'max_cat_to_onehot': 10, 'sampling_method': 'uniform', 'scale_pos_weight': 5.5229702111895085}. Best is trial 1 with value: 0.901327056753425.\n",
            "[I 2025-09-09 19:37:34,068] Trial 8 finished with value: 0.900162588476334 and parameters: {'eta': 0.10973138878313957, 'max_depth': 11, 'min_child_weight': 1.9243507832795548, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_lambda': 1.5217588011309356e-05, 'reg_alpha': 0.010153481926590753, 'gamma': 6.886820979154339, 'grow_policy': 'depthwise', 'max_bin': 256, 'max_cat_to_onehot': 1, 'sampling_method': 'uniform', 'scale_pos_weight': 3.529214506325335}. Best is trial 1 with value: 0.901327056753425.\n",
            "[I 2025-09-09 19:48:34,326] Trial 9 finished with value: 0.8869029057746592 and parameters: {'eta': 0.0907059090794797, 'max_depth': 9, 'min_child_weight': 3.487347771537349, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_lambda': 1.4858725016827186, 'reg_alpha': 0.011891211549340622, 'gamma': 9.725623615137925, 'grow_policy': 'depthwise', 'max_bin': 64, 'max_cat_to_onehot': 1, 'sampling_method': 'uniform', 'scale_pos_weight': 0.6663421266766357}. Best is trial 1 with value: 0.901327056753425.\n",
            "[I 2025-09-09 19:51:30,249] Trial 10 finished with value: 0.8926428616960406 and parameters: {'eta': 0.022446708845225607, 'max_depth': 12, 'min_child_weight': 14.349942714281825, 'subsample': 1.0, 'colsample_bytree': 0.85, 'reg_lambda': 0.000497772827651598, 'reg_alpha': 0.00025044143818153485, 'gamma': 3.2115450032672297, 'grow_policy': 'depthwise', 'max_bin': 128, 'max_cat_to_onehot': 2, 'sampling_method': 'uniform', 'scale_pos_weight': 6.87424453303332}. Best is trial 1 with value: 0.901327056753425.\n",
            "[I 2025-09-09 19:59:03,889] Trial 11 finished with value: 0.9002100307214015 and parameters: {'eta': 0.15115705052098735, 'max_depth': 12, 'min_child_weight': 1.0451235591259134, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_lambda': 4.654482873887654e-05, 'reg_alpha': 0.0020605224098539337, 'gamma': 5.531180569307227, 'grow_policy': 'depthwise', 'max_bin': 256, 'max_cat_to_onehot': 2, 'sampling_method': 'uniform', 'scale_pos_weight': 2.913227590577607}. Best is trial 1 with value: 0.901327056753425.\n",
            "[I 2025-09-09 20:00:11,743] Trial 12 finished with value: 0.8944523074610228 and parameters: {'eta': 0.17791077501088182, 'max_depth': 12, 'min_child_weight': 1.0011215892009748, 'subsample': 1.0, 'colsample_bytree': 0.5, 'reg_lambda': 0.00011479417653524493, 'reg_alpha': 0.0007811854872740026, 'gamma': 5.171139235235829, 'grow_policy': 'depthwise', 'max_bin': 256, 'max_cat_to_onehot': 2, 'sampling_method': 'uniform', 'scale_pos_weight': 2.3705224463455137}. Best is trial 1 with value: 0.901327056753425.\n",
            "[I 2025-09-09 20:10:11,892] Trial 13 finished with value: 0.9024980953105665 and parameters: {'eta': 0.14401583460052106, 'max_depth': 10, 'min_child_weight': 1.1609584540906812, 'subsample': 0.85, 'colsample_bytree': 0.5, 'reg_lambda': 0.00023453592921871645, 'reg_alpha': 0.0005005302752417924, 'gamma': 2.4510111691076486, 'grow_policy': 'depthwise', 'max_bin': 256, 'max_cat_to_onehot': 2, 'sampling_method': 'uniform', 'scale_pos_weight': 2.996404774820341}. Best is trial 13 with value: 0.9024980953105665.\n",
            "[I 2025-09-09 20:24:43,218] Trial 14 finished with value: 0.9030659394173449 and parameters: {'eta': 0.06362927881689012, 'max_depth': 10, 'min_child_weight': 1.4072873807142292, 'subsample': 0.85, 'colsample_bytree': 0.5, 'reg_lambda': 0.02429696916434397, 'reg_alpha': 0.00011811226900033988, 'gamma': 1.7308722510883305, 'grow_policy': 'depthwise', 'max_bin': 256, 'max_cat_to_onehot': 2, 'sampling_method': 'uniform', 'scale_pos_weight': 1.5096466460622118}. Best is trial 14 with value: 0.9030659394173449.\n",
            "[I 2025-09-09 20:38:04,099] Trial 15 finished with value: 0.900088240273462 and parameters: {'eta': 0.07758785133829832, 'max_depth': 10, 'min_child_weight': 9.414878218844754, 'subsample': 0.85, 'colsample_bytree': 0.5, 'reg_lambda': 0.019377015222916075, 'reg_alpha': 7.312714067734906e-05, 'gamma': 1.4947884116102501, 'grow_policy': 'depthwise', 'max_bin': 256, 'max_cat_to_onehot': 2, 'sampling_method': 'uniform', 'scale_pos_weight': 0.6973162147132559}. Best is trial 14 with value: 0.9030659394173449.\n",
            "[I 2025-09-09 20:52:01,183] Trial 16 finished with value: 0.8996783444878433 and parameters: {'eta': 0.0637854615721107, 'max_depth': 10, 'min_child_weight': 1.3557976595273589, 'subsample': 0.85, 'colsample_bytree': 0.5, 'reg_lambda': 0.012740499577728931, 'reg_alpha': 1.0376427623642677e-06, 'gamma': 2.180924910044791, 'grow_policy': 'depthwise', 'max_bin': 128, 'max_cat_to_onehot': 2, 'sampling_method': 'uniform', 'scale_pos_weight': 1.330476619265504}. Best is trial 14 with value: 0.9030659394173449.\n",
            "[I 2025-09-09 21:10:11,238] Trial 17 finished with value: 0.9028850455678483 and parameters: {'eta': 0.022826978155234167, 'max_depth': 10, 'min_child_weight': 2.4562327795734387, 'subsample': 0.85, 'colsample_bytree': 0.5, 'reg_lambda': 0.0012732735277180705, 'reg_alpha': 0.0001470669235121373, 'gamma': 1.1928397199001832, 'grow_policy': 'depthwise', 'max_bin': 256, 'max_cat_to_onehot': 2, 'sampling_method': 'uniform', 'scale_pos_weight': 3.4676080625657253}. Best is trial 14 with value: 0.9030659394173449.\n",
            "[I 2025-09-09 21:30:04,628] Trial 18 finished with value: 0.9020559269641251 and parameters: {'eta': 0.022250802033832236, 'max_depth': 8, 'min_child_weight': 2.972921926226717, 'subsample': 0.85, 'colsample_bytree': 0.85, 'reg_lambda': 0.001919935690205218, 'reg_alpha': 2.1091612391177148e-05, 'gamma': 0.2884413471400302, 'grow_policy': 'lossguide', 'max_bin': 256, 'max_cat_to_onehot': 2, 'sampling_method': 'uniform', 'scale_pos_weight': 4.742351569832311}. Best is trial 14 with value: 0.9030659394173449.\n",
            "[I 2025-09-09 21:33:31,713] Trial 19 finished with value: 0.8939433474113316 and parameters: {'eta': 0.030199806175445727, 'max_depth': 11, 'min_child_weight': 2.412878166310408, 'subsample': 1.0, 'colsample_bytree': 0.5, 'reg_lambda': 0.08389148042570285, 'reg_alpha': 1.286453048096474e-06, 'gamma': 1.174547092650054, 'grow_policy': 'depthwise', 'max_bin': 128, 'max_cat_to_onehot': 2, 'sampling_method': 'uniform', 'scale_pos_weight': 1.5295955336736125}. Best is trial 14 with value: 0.9030659394173449.\n",
            "[I 2025-09-09 21:47:07,312] Trial 20 finished with value: 0.8996878931715642 and parameters: {'eta': 0.04749052996350766, 'max_depth': 9, 'min_child_weight': 8.735534265803068, 'subsample': 0.85, 'colsample_bytree': 0.5, 'reg_lambda': 0.12701052445424335, 'reg_alpha': 0.00010215042954159731, 'gamma': 3.658962345185499, 'grow_policy': 'depthwise', 'max_bin': 256, 'max_cat_to_onehot': 2, 'sampling_method': 'uniform', 'scale_pos_weight': 3.257359371741981}. Best is trial 14 with value: 0.9030659394173449.\n",
            "[I 2025-09-09 21:55:41,622] Trial 21 finished with value: 0.9022239870776657 and parameters: {'eta': 0.19806126489389858, 'max_depth': 10, 'min_child_weight': 1.3283368078280917, 'subsample': 0.85, 'colsample_bytree': 0.5, 'reg_lambda': 0.00043173572941273956, 'reg_alpha': 0.0005584791722317553, 'gamma': 2.6971473214014123, 'grow_policy': 'depthwise', 'max_bin': 256, 'max_cat_to_onehot': 2, 'sampling_method': 'uniform', 'scale_pos_weight': 2.9518252747697447}. Best is trial 14 with value: 0.9030659394173449.\n",
            "[I 2025-09-09 22:05:48,291] Trial 22 finished with value: 0.9031766516531127 and parameters: {'eta': 0.07690013575165573, 'max_depth': 11, 'min_child_weight': 1.399856728745255, 'subsample': 0.85, 'colsample_bytree': 0.5, 'reg_lambda': 0.00046823259526695716, 'reg_alpha': 0.003141640187603369, 'gamma': 1.870395577060695, 'grow_policy': 'depthwise', 'max_bin': 256, 'max_cat_to_onehot': 2, 'sampling_method': 'uniform', 'scale_pos_weight': 3.9351479278590102}. Best is trial 22 with value: 0.9031766516531127.\n",
            "[I 2025-09-09 22:14:16,968] Trial 23 finished with value: 0.902933666416842 and parameters: {'eta': 0.06939291927046767, 'max_depth': 11, 'min_child_weight': 2.3914293088225946, 'subsample': 0.85, 'colsample_bytree': 0.5, 'reg_lambda': 0.003371722762063227, 'reg_alpha': 0.0044102647166139215, 'gamma': 1.4647834904938506, 'grow_policy': 'depthwise', 'max_bin': 256, 'max_cat_to_onehot': 2, 'sampling_method': 'uniform', 'scale_pos_weight': 5.12915609247754}. Best is trial 22 with value: 0.9031766516531127.\n",
            "[I 2025-09-09 22:22:20,426] Trial 24 finished with value: 0.9029108012281425 and parameters: {'eta': 0.07148015417841914, 'max_depth': 11, 'min_child_weight': 1.5485260443886812, 'subsample': 0.85, 'colsample_bytree': 0.5, 'reg_lambda': 0.007624407787906229, 'reg_alpha': 0.0035748709853048815, 'gamma': 1.5970085125141869, 'grow_policy': 'depthwise', 'max_bin': 256, 'max_cat_to_onehot': 2, 'sampling_method': 'uniform', 'scale_pos_weight': 5.2144768528656344}. Best is trial 22 with value: 0.9031766516531127.\n",
            "[I 2025-09-09 22:27:57,981] Trial 25 finished with value: 0.9028842732861942 and parameters: {'eta': 0.05134805641125341, 'max_depth': 11, 'min_child_weight': 2.090839562830365, 'subsample': 0.85, 'colsample_bytree': 0.85, 'reg_lambda': 0.03460123284460546, 'reg_alpha': 0.028226866294012803, 'gamma': 0.0902934184903208, 'grow_policy': 'depthwise', 'max_bin': 256, 'max_cat_to_onehot': 2, 'sampling_method': 'uniform', 'scale_pos_weight': 6.183707545965871}. Best is trial 22 with value: 0.9031766516531127.\n",
            "[I 2025-09-09 22:39:36,222] Trial 26 finished with value: 0.9029127724804893 and parameters: {'eta': 0.07604542557242239, 'max_depth': 11, 'min_child_weight': 1.3770497431727877, 'subsample': 0.85, 'colsample_bytree': 0.5, 'reg_lambda': 0.8493740250121323, 'reg_alpha': 0.0014079732343384528, 'gamma': 2.0749638413760856, 'grow_policy': 'lossguide', 'max_bin': 256, 'max_cat_to_onehot': 2, 'sampling_method': 'uniform', 'scale_pos_weight': 4.138142187816794}. Best is trial 22 with value: 0.9031766516531127.\n",
            "[I 2025-09-09 22:41:31,188] Trial 27 finished with value: 0.8884998155183338 and parameters: {'eta': 0.05706998436993695, 'max_depth': 8, 'min_child_weight': 2.2599856153035933, 'subsample': 1.0, 'colsample_bytree': 0.5, 'reg_lambda': 0.0036418391785410903, 'reg_alpha': 0.016189744587965415, 'gamma': 4.03004938218087, 'grow_policy': 'depthwise', 'max_bin': 256, 'max_cat_to_onehot': 2, 'sampling_method': 'uniform', 'scale_pos_weight': 4.723759453842177}. Best is trial 22 with value: 0.9031766516531127.\n",
            "[I 2025-09-09 22:50:05,108] Trial 28 finished with value: 0.898425097916658 and parameters: {'eta': 0.08713888170158955, 'max_depth': 9, 'min_child_weight': 2.950944290247708, 'subsample': 0.5, 'colsample_bytree': 0.5, 'reg_lambda': 7.989664236398905e-05, 'reg_alpha': 0.0032674670665082057, 'gamma': 0.8101237782998365, 'grow_policy': 'depthwise', 'max_bin': 128, 'max_cat_to_onehot': 2, 'sampling_method': 'uniform', 'scale_pos_weight': 6.328802912381821}. Best is trial 22 with value: 0.9031766516531127.\n",
            "[I 2025-09-09 23:06:18,428] Trial 29 finished with value: 0.8975618912091224 and parameters: {'eta': 0.040956482708972446, 'max_depth': 11, 'min_child_weight': 3.799147004122746, 'subsample': 0.85, 'colsample_bytree': 0.5, 'reg_lambda': 0.001037625916536915, 'reg_alpha': 4.6940390213619264e-06, 'gamma': 3.0715668299513403, 'grow_policy': 'lossguide', 'max_bin': 64, 'max_cat_to_onehot': 1, 'sampling_method': 'uniform', 'scale_pos_weight': 5.057020828737215}. Best is trial 22 with value: 0.9031766516531127.\n",
            "[I 2025-09-09 23:19:40,000] Trial 30 finished with value: 0.8883664314111321 and parameters: {'eta': 0.06918167621443279, 'max_depth': 4, 'min_child_weight': 1.558678770485942, 'subsample': 0.85, 'colsample_bytree': 0.85, 'reg_lambda': 0.4501096624562984, 'reg_alpha': 4.7582944327743395e-05, 'gamma': 4.36611913547594, 'grow_policy': 'depthwise', 'max_bin': 64, 'max_cat_to_onehot': 2, 'sampling_method': 'uniform', 'scale_pos_weight': 6.117564025815059}. Best is trial 22 with value: 0.9031766516531127.\n",
            "[I 2025-09-09 23:34:28,782] Trial 31 finished with value: 0.9013882404281853 and parameters: {'eta': 0.08192842053464784, 'max_depth': 11, 'min_child_weight': 1.2225281231918765, 'subsample': 0.85, 'colsample_bytree': 0.5, 'reg_lambda': 32.183856641025386, 'reg_alpha': 0.001205601179568436, 'gamma': 2.1571984493676073, 'grow_policy': 'lossguide', 'max_bin': 256, 'max_cat_to_onehot': 2, 'sampling_method': 'uniform', 'scale_pos_weight': 4.139147484897704}. Best is trial 22 with value: 0.9031766516531127.\n",
            "[I 2025-09-09 23:49:18,565] Trial 32 finished with value: 0.9027848525050605 and parameters: {'eta': 0.05457006245752589, 'max_depth': 12, 'min_child_weight': 1.4868291098141575, 'subsample': 0.85, 'colsample_bytree': 0.5, 'reg_lambda': 5.514479293224184, 'reg_alpha': 0.055059330631432334, 'gamma': 1.6199661944029198, 'grow_policy': 'lossguide', 'max_bin': 256, 'max_cat_to_onehot': 2, 'sampling_method': 'uniform', 'scale_pos_weight': 3.904662893932821}. Best is trial 22 with value: 0.9031766516531127.\n",
            "[I 2025-09-09 23:58:48,725] Trial 33 finished with value: 0.9022275780316316 and parameters: {'eta': 0.10394612739139807, 'max_depth': 10, 'min_child_weight': 1.7026824900594304, 'subsample': 0.85, 'colsample_bytree': 0.5, 'reg_lambda': 7.968246103643603, 'reg_alpha': 0.0043145447363145024, 'gamma': 0.7687210521241783, 'grow_policy': 'lossguide', 'max_bin': 256, 'max_cat_to_onehot': 2, 'sampling_method': 'uniform', 'scale_pos_weight': 4.374117518883125}. Best is trial 22 with value: 0.9031766516531127.\n",
            "[I 2025-09-10 00:03:12,900] Trial 34 finished with value: 0.903164475730929 and parameters: {'eta': 0.12601131488969086, 'max_depth': 12, 'min_child_weight': 1.2234277804188702, 'subsample': 0.85, 'colsample_bytree': 1.0, 'reg_lambda': 0.3338482167713757, 'reg_alpha': 0.00022445093617232776, 'gamma': 1.8922417390520891, 'grow_policy': 'lossguide', 'max_bin': 256, 'max_cat_to_onehot': 1, 'sampling_method': 'uniform', 'scale_pos_weight': 3.7876204641143}. Best is trial 22 with value: 0.9031766516531127.\n",
            "[I 2025-09-10 00:09:59,901] Trial 35 finished with value: 0.9025081065896263 and parameters: {'eta': 0.1269887943079296, 'max_depth': 12, 'min_child_weight': 1.1563432524492412, 'subsample': 0.85, 'colsample_bytree': 1.0, 'reg_lambda': 0.3612560878070444, 'reg_alpha': 0.00030061375045343245, 'gamma': 3.290202960633648, 'grow_policy': 'lossguide', 'max_bin': 256, 'max_cat_to_onehot': 1, 'sampling_method': 'uniform', 'scale_pos_weight': 1.9615515401670325}. Best is trial 22 with value: 0.9031766516531127.\n",
            "[I 2025-09-10 00:17:38,778] Trial 36 finished with value: 0.9028980737248167 and parameters: {'eta': 0.06550153645600344, 'max_depth': 12, 'min_child_weight': 1.9371092649228197, 'subsample': 0.85, 'colsample_bytree': 1.0, 'reg_lambda': 0.030872419293835312, 'reg_alpha': 1.8441261145473242e-05, 'gamma': 2.7321074183698757, 'grow_policy': 'lossguide', 'max_bin': 256, 'max_cat_to_onehot': 1, 'sampling_method': 'uniform', 'scale_pos_weight': 5.722425745850652}. Best is trial 22 with value: 0.9031766516531127.\n",
            "[I 2025-09-10 00:30:27,537] Trial 37 finished with value: 0.8998388141062431 and parameters: {'eta': 0.13555555023635812, 'max_depth': 7, 'min_child_weight': 2.5543391557636106, 'subsample': 0.5, 'colsample_bytree': 1.0, 'reg_lambda': 0.006019369287852478, 'reg_alpha': 7.137688945000408, 'gamma': 0.665620920391417, 'grow_policy': 'depthwise', 'max_bin': 256, 'max_cat_to_onehot': 1, 'sampling_method': 'uniform', 'scale_pos_weight': 7.357071492576372}. Best is trial 22 with value: 0.9031766516531127.\n",
            "[I 2025-09-10 00:35:03,763] Trial 38 finished with value: 0.9001148454765909 and parameters: {'eta': 0.11681842782809716, 'max_depth': 11, 'min_child_weight': 1.6538862196015591, 'subsample': 0.7, 'colsample_bytree': 1.0, 'reg_lambda': 0.0653573212702068, 'reg_alpha': 0.007709530682406838, 'gamma': 1.8743678131123218, 'grow_policy': 'lossguide', 'max_bin': 128, 'max_cat_to_onehot': 1, 'sampling_method': 'uniform', 'scale_pos_weight': 3.7630135022511633}. Best is trial 22 with value: 0.9031766516531127.\n",
            "[I 2025-09-10 00:47:31,199] Trial 39 finished with value: 0.8978877457331544 and parameters: {'eta': 0.03915442784015949, 'max_depth': 12, 'min_child_weight': 1.1799775075064203, 'subsample': 0.85, 'colsample_bytree': 1.0, 'reg_lambda': 0.010463419790635618, 'reg_alpha': 0.5958877277711726, 'gamma': 8.573636815036384, 'grow_policy': 'depthwise', 'max_bin': 256, 'max_cat_to_onehot': 10, 'sampling_method': 'uniform', 'scale_pos_weight': 2.578600483702174}. Best is trial 22 with value: 0.9031766516531127.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best trial:\n",
            "  value (mean CV PR-AUC): 0.9031766516531127\n",
            "  params:\n",
            "    eta: 0.07690013575165573\n",
            "    max_depth: 11\n",
            "    min_child_weight: 1.399856728745255\n",
            "    subsample: 0.85\n",
            "    colsample_bytree: 0.5\n",
            "    reg_lambda: 0.00046823259526695716\n",
            "    reg_alpha: 0.003141640187603369\n",
            "    gamma: 1.870395577060695\n",
            "    grow_policy: depthwise\n",
            "    max_bin: 256\n",
            "    max_cat_to_onehot: 2\n",
            "    sampling_method: uniform\n",
            "    scale_pos_weight: 3.9351479278590102\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ======================================\n",
        "# CV & Optuna objective (wider search)\n",
        "# ======================================\n",
        "CV = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
        "\n",
        "def split_fn():\n",
        "    return CV.split(X_trval, Y_trval)\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        \"tree_method\": \"hist\",\n",
        "        \"objective\": \"binary:logistic\",\n",
        "        \"eval_metric\": \"aucpr\",  # keep for early stopping; we're optimizing F1 ourselves\n",
        "        \"eta\": trial.suggest_float(\"eta\", 0.02, 0.20, log=True),\n",
        "        \"max_depth\": trial.suggest_int(\"max_depth\", 4, 12),\n",
        "        \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 1.0, 20.0, log=True),\n",
        "        \"subsample\": trial.suggest_categorical(\"subsample\", [0.5, 0.7, 0.85, 1.0]),\n",
        "        \"colsample_bytree\": trial.suggest_categorical(\"colsample_bytree\", [0.5, 0.7, 0.85, 1.0]),\n",
        "        \"lambda\": trial.suggest_float(\"reg_lambda\", 1e-6, 50.0, log=True),\n",
        "        \"alpha\":  trial.suggest_float(\"reg_alpha\",  1e-6, 20.0, log=True),\n",
        "        \"gamma\": trial.suggest_float(\"gamma\", 0.0, 10.0),\n",
        "        \"grow_policy\": trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"]),\n",
        "        \"max_bin\": trial.suggest_categorical(\"max_bin\", [64, 128, 256]),\n",
        "        \"max_cat_to_onehot\": trial.suggest_categorical(\"max_cat_to_onehot\", [1, 2, 10]),\n",
        "        \"sampling_method\": trial.suggest_categorical(\"sampling_method\", [\"uniform\"]),  # CPU-safe\n",
        "        \"scale_pos_weight\": trial.suggest_float(\"scale_pos_weight\", 0.25*scale_pos_weight, 4.0*scale_pos_weight),\n",
        "        \"seed\": 123,\n",
        "    }\n",
        "\n",
        "    f1s = []\n",
        "    for tr_idx, va_idx in split_fn():\n",
        "        dtr = xgb.DMatrix(X_trval.iloc[tr_idx], label=Y_trval.iloc[tr_idx], enable_categorical=True)\n",
        "        dva = xgb.DMatrix(X_trval.iloc[va_idx], label=Y_trval.iloc[va_idx], enable_categorical=True)\n",
        "\n",
        "        booster = xgb.train(\n",
        "            params,\n",
        "            dtr,\n",
        "            num_boost_round=4000,\n",
        "            evals=[(dva, \"val\")],\n",
        "            early_stopping_rounds=150,\n",
        "            verbose_eval=False,\n",
        "        )\n",
        "\n",
        "        proba = booster.predict(dva, iteration_range=(0, booster.best_iteration + 1))\n",
        "        # pick best threshold by F1 on the validation fold (class 1 focus)\n",
        "        thr, f1_fold, p_fold, r_fold = pick_threshold_max_f1(Y_trval.iloc[va_idx], proba)\n",
        "        f1s.append(float(f1_fold))\n",
        "\n",
        "    # Optuna will MAXIMIZE this mean F1\n",
        "    return float(np.mean(f1s))\n",
        "\n",
        "\n",
        "# Run the Optuna study\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=40, show_progress_bar=False)\n",
        "print(\"Best trial:\")\n",
        "print(\"  value (mean CV PR-AUC):\", study.best_value)\n",
        "print(\"  params:\")\n",
        "for k, v in study.best_params.items():\n",
        "    print(f\"    {k}: {v}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Top Trial — TEST (precision floor) RESULTS ===\n",
            "Confusion Matrix [rows=true 0/1, cols=pred 0/1]: [[122641   6946]\n",
            " [  6831  63582]]\n",
            "Metrics:\n",
            "  precision: 0.90151\n",
            "  recall: 0.90299\n",
            "  f1: 0.90225\n",
            "  pr_auc: 0.97290\n",
            "Classification Report:               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9472    0.9464    0.9468    129587\n",
            "           1     0.9015    0.9030    0.9022     70413\n",
            "\n",
            "    accuracy                         0.9311    200000\n",
            "   macro avg     0.9244    0.9247    0.9245    200000\n",
            "weighted avg     0.9311    0.9311    0.9311    200000\n",
            "\n",
            "=== Top Trial — UNSEEN (precision floor) RESULTS ===\n",
            "Confusion Matrix [rows=true 0/1, cols=pred 0/1]: [[6142  327]\n",
            " [ 310 3221]]\n",
            "Metrics:\n",
            "  precision: 0.90784\n",
            "  recall: 0.91221\n",
            "  f1: 0.91002\n",
            "  pr_auc: 0.97371\n",
            "Classification Report:               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9520    0.9495    0.9507      6469\n",
            "           1     0.9078    0.9122    0.9100      3531\n",
            "\n",
            "    accuracy                         0.9363     10000\n",
            "   macro avg     0.9299    0.9308    0.9304     10000\n",
            "weighted avg     0.9364    0.9363    0.9363     10000\n",
            "\n",
            "=== Top Trials Comparison (metrics at each trial's precision-floor threshold) ===\n",
            " rank  trial  mean_cv_pr_auc  n_estimators      thr  TEST_f1  TEST_precision  TEST_recall  TEST_pr_auc  UNSEEN_f1  UNSEEN_precision  UNSEEN_recall  UNSEEN_pr_auc\n",
            "    1     22        0.903177          2317 0.687786 0.902250        0.901514     0.902987     0.972897   0.910016          0.907835       0.912206       0.973706\n",
            "    2     34        0.903164           428 0.681868 0.901912        0.900571     0.903257     0.972975   0.910939          0.907991       0.913905       0.973741\n",
            "    3     14        0.903066          3741 0.471325 0.901750        0.901308     0.902191     0.972657   0.909914          0.908757       0.911073       0.973686\n",
            "Saved: xgb_claims_binmodel_nativecat.joblib\n"
          ]
        }
      ],
      "source": [
        "# ----------------------------------------------\n",
        "# Evaluate top-K trials (refit + TEST/UNSEEN under precision constraint)\n",
        "# ----------------------------------------------\n",
        "\n",
        "from pandas.api.types import CategoricalDtype as _CatDType\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
        "\n",
        "# --- Helper: smallest threshold that meets precision_floor (maximizes recall under the constraint)\n",
        "def threshold_for_precision(y_true, proba, precision_floor=0.90):\n",
        "    p, r, thr = precision_recall_curve(y_true, proba)\n",
        "    # Walk thresholds in ascending order; pick the smallest meeting the floor\n",
        "    for P, T in zip(p[:-1], thr):  # last precision has no corresponding threshold\n",
        "        if P >= precision_floor:\n",
        "            return float(T)\n",
        "    # If nothing meets the floor, fall back to the largest available threshold (max precision)\n",
        "    return float(thr[-1]) if len(thr) else 0.5\n",
        "\n",
        "# --- OOF: pick threshold to maximize recall with precision >= floor; also get median best n_estimators\n",
        "def get_oof_threshold_and_n(X_ref, y_ref, params, precision_floor=0.90):\n",
        "    oof_proba = np.full(shape=(len(y_ref),), fill_value=np.nan, dtype=float)\n",
        "    best_iterations = []\n",
        "    for tr_idx, va_idx in split_fn():\n",
        "        dtr = xgb.DMatrix(X_ref.iloc[tr_idx], label=y_ref.iloc[tr_idx], enable_categorical=True)\n",
        "        dva = xgb.DMatrix(X_ref.iloc[va_idx], label=y_ref.iloc[va_idx], enable_categorical=True)\n",
        "        booster = xgb.train(\n",
        "            params,\n",
        "            dtr,\n",
        "            num_boost_round=4000,\n",
        "            evals=[(dva, \"val\")],\n",
        "            early_stopping_rounds=150,\n",
        "            verbose_eval=False,\n",
        "        )\n",
        "        proba = booster.predict(dva, iteration_range=(0, booster.best_iteration + 1))\n",
        "        oof_proba[va_idx] = proba\n",
        "        best_iterations.append(int(booster.best_iteration) + 1)\n",
        "\n",
        "    assert np.isfinite(oof_proba).all(), \"OOF predictions contain NaNs\"\n",
        "\n",
        "    # Choose operating point: smallest threshold with precision >= floor (thus highest recall under the constraint)\n",
        "    thr = threshold_for_precision(y_ref, oof_proba, precision_floor=precision_floor)\n",
        "\n",
        "    # Keep same return signature/names\n",
        "    n_estimators = int(np.median(best_iterations))\n",
        "    pr_oof = float(average_precision_score(y_ref, oof_proba))\n",
        "    return float(thr), n_estimators, pr_oof\n",
        "\n",
        "# Prepare UNSEEN target and alignment helper\n",
        "if 'DenialFlag' in df_unseen.columns:\n",
        "    try:\n",
        "        y_unseen = df_unseen['DenialFlag'].astype(int)\n",
        "    except Exception:\n",
        "        y_unseen = None\n",
        "else:\n",
        "    y_unseen = None\n",
        "\n",
        "# Lock categorical category lists for alignment\n",
        "cat_dtype_map = {c: list(cat_dtypes[c].categories) for c in cat_dtypes}\n",
        "feature_cols = X.columns.tolist()\n",
        "\n",
        "def align_to_training_native(df_raw: pd.DataFrame, feature_cols: list, cat_dtype_map: dict) -> pd.DataFrame:\n",
        "    dfX = df_raw.copy()\n",
        "    # Drop target if present\n",
        "    if 'DenialFlag' in dfX.columns:\n",
        "        dfX = dfX.drop(columns=['DenialFlag'])\n",
        "    # Add any missing columns\n",
        "    for c in feature_cols:\n",
        "        if c not in dfX.columns:\n",
        "            if c in cat_dtype_map:\n",
        "                dfX[c] = pd.Series(pd.Categorical([None]*len(dfX), dtype=_CatDType(cat_dtype_map[c])))\n",
        "            else:\n",
        "                dfX[c] = 0\n",
        "    # Enforce categorical dtypes with locked categories\n",
        "    for c, cats in cat_dtype_map.items():\n",
        "        if c in dfX.columns:\n",
        "            dfX[c] = dfX[c].astype(_CatDType(cats))\n",
        "    # Reorder\n",
        "    return dfX[feature_cols]\n",
        "\n",
        "# Build UNSEEN features aligned to TRAIN\n",
        "X_unseen = align_to_training_native(df_unseen, feature_cols, cat_dtype_map)\n",
        "\n",
        "# Select top-K trials by CV PR-AUC\n",
        "top_k = 3\n",
        "ranked_trials = sorted(\n",
        "    study.trials,\n",
        "    key=lambda t: t.value if t.value is not None else -np.inf,\n",
        "    reverse=True\n",
        ")[:top_k]\n",
        "\n",
        "comparison_rows = []\n",
        "final_artifacts = None\n",
        "\n",
        "# You can tweak this floor if needed; default keeps signature compatibility\n",
        "_precision_floor = 0.90\n",
        "\n",
        "for rank, tr in enumerate(ranked_trials, start=1):\n",
        "    params = tr.params.copy()\n",
        "    params.update({\n",
        "        \"tree_method\": \"hist\",\n",
        "        \"objective\": \"binary:logistic\",\n",
        "        \"eval_metric\": \"aucpr\",\n",
        "        \"seed\": 123,\n",
        "    })\n",
        "\n",
        "    # OOF-based operating point that maximizes recall under precision >= floor\n",
        "    thr_i, n_i, pr_oof_i = get_oof_threshold_and_n(X_trval, Y_trval, params, precision_floor=_precision_floor)\n",
        "\n",
        "    xgb_refit = XGBClassifier(\n",
        "        tree_method=\"hist\",\n",
        "        objective=\"binary:logistic\",\n",
        "        eval_metric=None,\n",
        "        n_estimators=n_i,\n",
        "        learning_rate=params.get(\"eta\", 0.05),\n",
        "        max_depth=params.get(\"max_depth\", 8),\n",
        "        min_child_weight=params.get(\"min_child_weight\", 2),\n",
        "        subsample=params.get(\"subsample\", 0.9),\n",
        "        colsample_bytree=params.get(\"colsample_bytree\", 0.8),\n",
        "        reg_lambda=params.get(\"lambda\", 1.0),\n",
        "        reg_alpha=params.get(\"alpha\", 0.0),\n",
        "        gamma=params.get(\"gamma\", 0.0),\n",
        "        grow_policy=params.get(\"grow_policy\", \"depthwise\"),\n",
        "        max_bin=params.get(\"max_bin\", 256),\n",
        "        max_cat_to_onehot=params.get(\"max_cat_to_onehot\", 1),\n",
        "        sampling_method=params.get(\"sampling_method\", \"uniform\"),\n",
        "        random_state=123,\n",
        "        n_jobs=-1,\n",
        "        scale_pos_weight=params.get(\"scale_pos_weight\", scale_pos_weight),\n",
        "        enable_categorical=True,\n",
        "    )\n",
        "\n",
        "    # Ensure categorical dtype for refit inputs\n",
        "    for c, dt in cat_dtypes.items():\n",
        "        if c in X_trval: X_trval[c] = X_trval[c].astype(dt)\n",
        "        if c in X_test:  X_test[c]  = X_test[c].astype(dt)\n",
        "\n",
        "    xgb_refit.fit(X_trval, Y_trval)\n",
        "\n",
        "    # TEST eval at the recall-maximizing (precision-floor) threshold\n",
        "    proba_test = xgb_refit.predict_proba(X_test)[:, 1]\n",
        "    cm_test, metrics_test, _ = evaluate_at_threshold(y_test, proba_test, threshold=thr_i)\n",
        "\n",
        "    # UNSEEN eval (if labels exist)\n",
        "    unseen_summary = {\"f1\": np.nan, \"precision\": np.nan, \"recall\": np.nan, \"pr_auc\": np.nan}\n",
        "    if y_unseen is not None:\n",
        "        dfx_u = X_unseen.copy()\n",
        "        for c, cats in cat_dtype_map.items():\n",
        "            if c in dfx_u.columns:\n",
        "                dfx_u[c] = dfx_u[c].astype(_CatDType(cats))\n",
        "        proba_unseen = xgb_refit.predict_proba(dfx_u)[:, 1]\n",
        "        _, metrics_unseen, _ = evaluate_at_threshold(y_unseen, proba_unseen, threshold=thr_i)\n",
        "        unseen_summary = metrics_unseen\n",
        "\n",
        "    comparison_rows.append({\n",
        "        \"rank\": rank,\n",
        "        \"trial\": tr.number,\n",
        "        \"mean_cv_pr_auc\": float(tr.value) if tr.value is not None else np.nan,\n",
        "        \"n_estimators\": n_i,\n",
        "        \"thr\": float(thr_i),\n",
        "        \"TEST_f1\": float(metrics_test[\"f1\"]),\n",
        "        \"TEST_precision\": float(metrics_test[\"precision\"]),\n",
        "        \"TEST_recall\": float(metrics_test[\"recall\"]),\n",
        "        \"TEST_pr_auc\": float(metrics_test[\"pr_auc\"]),\n",
        "        \"UNSEEN_f1\": float(unseen_summary[\"f1\"]) if not np.isnan(unseen_summary[\"f1\"]) else np.nan,\n",
        "        \"UNSEEN_precision\": float(unseen_summary[\"precision\"]) if not np.isnan(unseen_summary[\"precision\"]) else np.nan,\n",
        "        \"UNSEEN_recall\": float(unseen_summary[\"recall\"]) if not np.isnan(unseen_summary[\"recall\"]) else np.nan,\n",
        "        \"UNSEEN_pr_auc\": float(unseen_summary[\"pr_auc\"]) if not np.isnan(unseen_summary[\"pr_auc\"]) else np.nan,\n",
        "    })\n",
        "\n",
        "    # Save the best-by-CV artifacts (first iteration is top-ranked)\n",
        "    if rank == 1:\n",
        "        # Keep key names the same\n",
        "        final_artifacts = {\n",
        "            \"model\": xgb_refit,\n",
        "            \"feature_cols\": feature_cols,\n",
        "            \"threshold\": float(thr_i),  # precision-floor operating point\n",
        "            \"categorical_cols\": categorical_cols,\n",
        "            \"cat_dtypes\": cat_dtype_map,\n",
        "            \"params\": params,\n",
        "        }\n",
        "        # Print detailed TEST/UNSEEN report for the top model\n",
        "        cmT, metT, repT = evaluate_at_threshold(y_test, proba_test, threshold=thr_i)\n",
        "        print_results(\"Top Trial — TEST (precision floor)\", cmT, metT, repT)\n",
        "        if y_unseen is not None:\n",
        "            cmU, metU, repU = evaluate_at_threshold(y_unseen, proba_unseen, threshold=thr_i)\n",
        "            print_results(\"Top Trial — UNSEEN (precision floor)\", cmU, metU, repU)\n",
        "\n",
        "# Show comparison across the top trials\n",
        "comp_df = pd.DataFrame(comparison_rows)\n",
        "print(\"=== Top Trials Comparison (metrics at each trial's precision-floor threshold) ===\")\n",
        "print(comp_df.to_string(index=False))\n",
        "\n",
        "# Persist artifacts for the best-by-CV model\n",
        "if final_artifacts is not None:\n",
        "    dump(final_artifacts, \"xgb_claims_binmodel_nativecat.joblib\")\n",
        "    print(\"Saved: xgb_claims_binmodel_nativecat.joblib\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: xgb_unseen_predictions_2025-09-10_01-19-32.csv\n",
            "        Clinic                     Service  AmountCharged CPTCode  ClientID  \\\n",
            "1322275     LO  Methadone Maintenance Week         114.00   H0020      4804   \n",
            "671232    B42C   Methadone Liquid 10mg/1ml           7.80   S0109      4314   \n",
            "251499     B41   Methadone Liquid 10mg/1ml           3.12   S0109      1552   \n",
            "1814187   V10A         Drug Screen BHG REF          49.71   80307     11092   \n",
            "498310    B42A       Individual Counseling          96.00   H0004      1133   \n",
            "\n",
            "                                  Payer    Provider      AuthStatus  \\\n",
            "1322275  Passport Health Plan by Molina  1932235363  Not Authorized   \n",
            "671232               Virginia Medicaid   1932696770             N/A   \n",
            "251499                    OptimaHealth   1932655313  Not Authorized   \n",
            "1814187       Colorado Medicaid Access   1952807943  Not Authorized   \n",
            "498310            Anthem HealthKeepers   1598252330  Not Authorized   \n",
            "\n",
            "           eligStatus DenialFlag  SameDayCli  DaysBetServiceToBilling  \\\n",
            "1322275  Not Verified          0           0                        1   \n",
            "671232            N/A          0           0                        6   \n",
            "251499   Not Verified          0           0                        6   \n",
            "1814187  Not Verified          1           0                        7   \n",
            "498310   Not Verified          0           0                        4   \n",
            "\n",
            "         xgb_proba  xgb_pred  DenialFlag_true  \n",
            "1322275   0.001666         0                0  \n",
            "671232    0.800100         1                0  \n",
            "251499    0.000048         0                0  \n",
            "1814187   0.696396         1                1  \n",
            "498310    0.001311         0                0  \n",
            "Share predicted positive (1) on unseen: 35.480% (n=10000)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ============================\n",
        "# PREDICT ON df_unseen (scored)\n",
        "# ============================\n",
        "\n",
        "# Score + classify with saved artifacts (already in memory)\n",
        "model = final_artifacts[\"model\"]\n",
        "feature_cols = final_artifacts[\"feature_cols\"]\n",
        "thr = float(final_artifacts[\"threshold\"])\n",
        "cat_dtype_map = final_artifacts[\"cat_dtypes\"]\n",
        "\n",
        "# Build X for the UNSEEN set (already engineered dates)\n",
        "X_unseen_for_scoring = align_to_training_native(df_unseen, feature_cols, cat_dtype_map)\n",
        "proba_unseen = model.predict_proba(X_unseen_for_scoring)[:, 1]\n",
        "pred_unseen  = (proba_unseen >= thr).astype(int)\n",
        "\n",
        "# Package results (keep ALL df_unseen columns)\n",
        "results_unseen = df_unseen.copy()\n",
        "results_unseen[\"xgb_proba\"] = proba_unseen\n",
        "results_unseen[\"xgb_pred\"]  = pred_unseen\n",
        "\n",
        "# Attach true labels if available\n",
        "if y_unseen is not None:\n",
        "    results_unseen[\"DenialFlag_true\"] = y_unseen.values\n",
        "\n",
        "# Save predictions\n",
        "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "file_name = f\"xgb_unseen_predictions_{timestamp}.csv\"\n",
        "results_unseen.to_csv(file_name, index=False)\n",
        "print(f\"Saved: {file_name}\")\n",
        "\n",
        "print(results_unseen.head())\n",
        "print(\n",
        "    f\"Share predicted positive (1) on unseen: \"\n",
        "    f\"{results_unseen['xgb_pred'].mean():.3%} (n={len(results_unseen)})\"\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "py313",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
